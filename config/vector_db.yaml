# NeuroRAG Vector Database Configuration

# FAISS Configuration
faiss:
  index_type: "IVF_FLAT"  # Options: FLAT, IVF_FLAT, IVF_PQ, HNSW
  dimension: 1536
  nlist: 1024  # Number of clusters for IVF
  nprobe: 64   # Number of clusters to search
  
  # Index file paths
  index_path: "/data/faiss_index.bin"
  metadata_path: "/data/documents.json"
  
  # Performance tuning
  omp_num_threads: 8
  use_gpu: false
  gpu_device: 0
  
  # Memory management
  max_memory_gb: 16
  mmap_enabled: true

# Pinecone Configuration (Alternative)
pinecone:
  api_key: "${PINECONE_API_KEY}"
  environment: "us-west1-gcp"
  index_name: "neurorag-vectors"
  dimension: 1536
  metric: "cosine"
  
  # Performance settings
  batch_size: 100
  max_retries: 3
  timeout_seconds: 30

# Embedding Model Configuration
embedding:
  model_name: "sentence-transformers/all-MiniLM-L6-v2"
  model_path: "/models/embedding_model"
  
  # Batch processing
  batch_size: 32
  max_sequence_length: 512
  normalize_embeddings: true
  
  # Caching
  cache_embeddings: true
  cache_ttl_hours: 24

# Search Configuration
search:
  default_k: 5
  max_k: 100
  similarity_threshold: 0.7
  
  # Reranking
  enable_reranking: true
  rerank_top_k: 20
  rerank_model: "cross-encoder/ms-marco-MiniLM-L-6-v2"
  
  # Filtering
  enable_metadata_filtering: true
  classification_filter: ["public", "confidential"]  # Exclude "restricted"

# Caching Configuration
cache:
  # Redis settings
  redis_url: "${REDIS_URL}"
  redis_password: "${REDIS_PASSWORD}"
  
  # Cache policies
  enable_query_cache: true
  enable_embedding_cache: true
  enable_result_cache: true
  
  # TTL settings (in seconds)
  query_cache_ttl: 3600      # 1 hour
  embedding_cache_ttl: 86400 # 24 hours
  result_cache_ttl: 1800     # 30 minutes
  
  # Cache sizes
  max_query_cache_size: 10000
  max_embedding_cache_size: 100000
  max_result_cache_size: 50000
  
  # Semantic caching
  semantic_cache_enabled: true
  semantic_similarity_threshold: 0.95
  semantic_cache_ttl: 7200  # 2 hours

# Performance Optimization
performance:
  # Threading
  num_worker_threads: 8
  io_thread_pool_size: 4
  
  # Batching
  enable_batch_processing: true
  batch_timeout_ms: 100
  max_batch_size: 64
  
  # Connection pooling
  max_connections: 100
  connection_timeout_seconds: 30
  
  # Memory optimization
  enable_memory_mapping: true
  prefetch_size: 1000
  
# Monitoring and Logging
monitoring:
  # Metrics collection
  enable_metrics: true
  metrics_port: 9090
  
  # Performance tracking
  track_latency: true
  track_throughput: true
  track_cache_hit_rate: true
  
  # Logging
  log_level: "INFO"
  log_queries: true
  log_slow_queries_ms: 100
  
  # Health checks
  health_check_interval_seconds: 30
  health_check_timeout_seconds: 5

# Security
security:
  # Access control
  enable_authentication: true
  api_key_required: true
  
  # Rate limiting
  enable_rate_limiting: true
  requests_per_minute: 1000
  burst_size: 100
  
  # Data protection
  encrypt_at_rest: true
  encrypt_in_transit: true
  
# Development Settings
development:
  debug_mode: false
  enable_profiling: false
  mock_embeddings: false
  
  # Testing
  test_data_path: "/data/test_queries.json"
  benchmark_on_startup: false